**РЕФЕРАТ**

**ПО ДИСЦИПЛИНЕ**

**«ИНФОРМАЦИОННЫЕ ТЕХНОЛОГИИ»**

«Суперкомпьютерные вычисления»


**Введение**

Целью создания реферата является представление технологий в области суперкомпьютерных систем и способов  связи с существующими областями науки и промышленности, нуждающимися в высокопроизводительных вычислениях   и моделировании.
  В то время, когда появились первые компьютеры, перед разработчиками вычислительной техники стала проблема - производительность вычислительной системы. С годами производительность компьютеров стремительно возрастала, с каждым годом росло и число пользователей компьютерами, что привело к расширению сферы вычислительных систем - это стало одной из причины появления суперкомпьютеров.

Суперкомпьютер - это обычная вычислительная система, которая позволяет производить сложные расчеты за более короткие промежутки времени. Система компьютера  состоит из трех компонентов - счетного устройства, блока памяти и вторичной системы хранения информации.
 Для чего нужны суперкомпьютеры? Расширение границ человеческого знания всегда опиралось на  теорию и опыт. Но теперь ученые сталкиваются с тем, что многие испытания стали невозможными - в некоторых случаях из-за своих масштабов, в других - дороговизны или опасности для здоровья и жизни людей. Тут-то и нашли применение  мощным компьютерам. Они позволяют экспериментировать, становятся опорой современной науки и производства.
 Иногда суперкомпьютеры используются для работы с одним-единственным приложением; в других случаях они обеспечивают выполнение большого числа разнообразных приложений. Теперь поподробнее рассмотрим что представляют из себя суперкомпьютерные вычисления.

**1.Суперкомпьютер и история его развития**

Суперкомпьютеры – это компьютерные системы, имеющие в настоящее время в не только максимальную производительность, но и максимальный объем оперативной и дисковой памяти. При этом не стоит забывать о специализированном программном обеспечении, с помощью которого можно эффективно всем этим воспользоваться. В качестве основной характеристики компьютеров для того, чтобы присвоить им префикс &quot;супер&quot;, используется такой показатель, как производительность – величина, показывающая, какое количество арифметических операций он может выполнить за единицу времени. При этом понятие суперкомпьютера не связано с какой-либо конкретной производительностью компьютера и носит исторический характер. Из истории высокопроизводительных вычислений видно как производительность, которая реализовывалась на суперкомпьютере, через 10 лет могла быть доступна на общедоступном персональном компьютере. В общем случае, можно говорить, что суперкомпьютер — это компьютер значительно более мощный, чем доступные для большинства пользователей компьютеры, а скорость технического прогресса сегодня такова, что нынешний лидер по производительности легко может стать через несколько лет обычной компьютерной системой, доступной простому пользователю. Определений суперкомпьютерам пытались давать много, иногда серьезных, иногда ироничных. Из-за большой гибкости самого термина до сих пор распространены довольно нечеткие представления о понятии «суперкомпьютер». Современные суперкомпьютеры весят несколько тонн, однако далеко не каждый тяжелый компьютер достоин чести считаться суперкомпьютером. Кен Батчер в 1998 предложил такой вариант: суперкомпьютер -это устройство, сводящее проблему вычислений к проблеме ввода/вывода. Иными словами, что раньше долго вычислялось, временами сбрасывая нечто на диск, на суперкомпьютере может выполниться мгновенно, переводя стрелки неэффективности на относительно медленные устройства ввода/вывода. Таким образом, подводя небольшой итог, можно утверждать, что определение понятия суперкомпьютер не раз было предметом многочисленных споров и дискуссий. Авторство термина «суперкомпьютер» приписывается Джорджу Мишелю и Сиднею Фернбачу, в конце 60-х годов XX века работавшим в Ливерморской национальной лаборатории и компании CDC. Тем не менее, известен тот факт, что еще в 1920 году газета New York World рассказывала о «супер вычислениях», выполняемых при помощи табулятора IBM, собранного по заказу Колумбийского университета. В общеупотребительный лексикон термин «суперкомпьютер» вошел благодаря распространенности компьютерных систем Сеймура Крея, таких как, CDC 6600, CDC 7600, Cray-1, -2, -3, -4. Сеймур Крей разрабатывал вычислительные машины, которые, по сути, становились основными вычислительными средствами правительственных, промышленных и академических научно-технических проектов США с середины 60-х годов до 1996 года. Суперкомпьютеры каждого типа создаются в небольшом количестве экземпляров, и обычно каждый тип суперкомпьютеров имеет определенные неповторимые архитектурные, технологические и вычислительные характеристики. В этой связи сравнение суперкомпьютеров весьма сложная задача, не имеющая однозначного решения. Тем не менее, разработаны определенные принципы условного сравнения компьютеров, что важно для их дальнейшего совершенствования и для продвижения на рынке. В соответствии с этими принципами суперкомпьютеры классифицируются в регулярно обновляемом списке Top500 (www.top500.org).Этот список обновляется два раза в год и носит общепризнанный, достаточно объективный характер.

**2. Суперкомпьютерные вычисления**

Вследствие все более широкого внедрения компьютерной техники и всеобщего повышения требований к уровню и качеству жизни наблюдается значительное усиление внимания к численному моделированию и вычислительным экспериментам. Численное моделирование, заполняя промежуток между физическими экспериментами и аналитическими подходами, позволило изучать явления, которые являются либо слишком сложными для исследования аналитическими методами, либо слишком дорогостоящими или опасными для экспериментального изучения. При этом вычислительный эксперимент позволил значительно удешевить процесс научного и технологического поиска. К сожалению, технологические возможности увеличения быстродействия процессоров ограничены по объективным причинам, связанным с физическими основами работы процессоров. Базовая проблема состоит в том, что увеличение быстродействия требует уменьшением размеров процессоров, а при малых размерах полупроводниковых элементов процессоров появляются трудности из-за квантово-механических эффектов, вносящих элементы недетерминированности. Следует констатировать, что эти трудности носят принципиальный характер и их пока что не удается преодолеть и вряд ли удастся преодолеть в будущем. Вследствие указанных выше причин для повышения производительности приходится идти по пути создания параллельных вычислительных систем, т.е. систем, в которых предусмотрена одновременная реализация ряда вычислительных процессов, связанных с решением одной задачи, на разных процессорных элементах. На современном этапе развития вычислительной техники такой способ, по-видимому, является основным, если не единственным, способом ускорения вычислений и достижения требуемой производительности. Высокопроизводительные вычисления –всегда параллельные -реализуются на устройствах, которые принято называть суперкомпьютерами. Подобные компьютеры всегда правильно ассоциируются с чем-то большим: огромные размеры, большие задачи, крупные фирмы и компании, невероятные скорости работы и стоимость установки и обслуживания. К суперкомпьютерам относят лишь те компьютерные системы, которые имеют максимальную производительность в настоящее время.

При изучении высокопроизводительных вычислений следует помнить, что в этой сфере деятельности все начинается с задач, задачами определяется и по результатам решения задач оценивается. Об этом нередко забывают, но это именно та идея, которая должна составлять фундамент любого суперкомпьютерного проекта, иметь максимальный приоритет при принятии решений на каждом этапе эго реализации. Вместе с тем, задачи, для решения которых создаются суперкомпьютер, полностью определяют особенности их компоновки, проектирования, технологического цикла производства и эксплуатации.

**3. Распределенные вычисления**

Распределённые вычисления — способ решения трудоёмких вычислительных задач с использованием нескольких компьютеров, чаще всего объединённых в [параллельную вычислительную систему. Распределённые вычисления применимы также в распределённых системах управления.

Последовательные вычисления в [распределённых системах выполняются с учётом одновременного решения многих задач. Особенностью распределённых многопроцессорных вычислительных систем, в отличие от локальных суперкомпьютеров, является возможность неограниченного наращивания производительности за счёт масштабирования. Слабосвязанные, гетерогенные вычислительные системы с высокой степенью распределения выделяют в отдельный класс распределённых систем —grid.

Работы по распределённым вычислениям с весьма прикладной целью — для военных нужд, а именно автоматизации процессов секретной связи и обработки разведывательной информации, велись интенсивно в США с 1960 гг. Разработкой технологий распределённых вычислений и созданием распределённых информационных систем в [Соединённых Штатах по заказу [Агентства по перспективным оборонным научно-исследовательским разработкам США](https://ru.wikipedia.org/wiki/%D0%90%D0%B3%D0%B5%D0%BD%D1%82%D1%81%D1%82%D0%B2%D0%BE_%D0%BF%D0%BE_%D0%BF%D0%B5%D1%80%D1%81%D0%BF%D0%B5%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D1%8B%D0%BC_%D0%BE%D0%B1%D0%BE%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%BC_%D0%BD%D0%B0%D1%83%D1%87%D0%BD%D0%BE-%D0%B8%D1%81%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D1%81%D0%BA%D0%B8%D0%BC_%D1%80%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0%D0%BC_%D0%A1%D0%A8%D0%90), [видов вооружённых сил](https://ru.wikipedia.org/wiki/%D0%92%D0%B8%D0%B4%D1%8B_%D0%B2%D0%BE%D0%BE%D1%80%D1%83%D0%B6%D1%91%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B8%D0%BB) и служб (агентств) в структуре [Министерства обороны США](https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BD%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D1%82%D0%B2%D0%BE_%D0%BE%D0%B1%D0%BE%D1%80%D0%BE%D0%BD%D1%8B_%D0%A1%D0%A8%D0%90) занимались исследовательские подразделения компаний и университетов

Распределённая ОС, динамически и автоматически распределяя работы по различным машинам системы для обработки, заставляет набор сетевых машин обрабатывать информацию параллельно. Пользователь распределённой ОС, вообще говоря, не имеет сведений о том, на какой машине выполняется его работа.

Распределённая ОС существует как единая операционная система в масштабах вычислительной системы. Каждый компьютер сети, работающей под управлением распределённой ОС, выполняет часть функций этой глобальной ОС. Распределённая ОС объединяет все компьютеры сети в том смысле, что они работают в тесной кооперации друг с другом для эффективного использования всех ресурсов компьютерной сети.

В результате сетевая ОС может рассматриваться как набор операционных систем отдельных компьютеров, составляющих сеть. На разных компьютерах сети могут выполняться одинаковые или разные ОС. Все операционные системы функционируют независимо друг от друга в том смысле, что каждая из них принимает независимые решения о создании и завершении своих собственных процессов и управлении локальными ресурсами. Но в любом случае операционные системы компьютеров, работающих в сети, должны включать взаимно согласованный набор коммуникационных протоколов для организации взаимодействия процессов, выполняющихся на разных компьютерах сети, и разделения ресурсов этих компьютеров между пользователями сети.

Если операционная система отдельного компьютера позволяет ему работать в сети, и может предоставлять свои ресурсы в общее пользование и/или использовать ресурсыдругих компьютеров сети, то такая операционная система отдельного компьютера также называется сетевой ОС.

Таким образом, термин «сетевая операционная система» используется в двух значениях: как совокупность ОС всех компьютеров сети и как операционная система отдельного компьютера, способного работать в сети. Из этого определения следует, что такие операционные системы, как, например, Windows NT, NetWare, Solaris, HP-UX, являются сетевыми, поскольку все они обладают средствами, которые позволяют их пользователям работать в сети.

**4. Параллельные вычисления**

Параллельные вычисления  — способ организации [компьютерных вычислений](https://ru.wikipedia.org/wiki/%D0%92%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%82%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B0), при котором [программы разрабатываются](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D0%B5%D1%81%D0%BF%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D1%8F) как набор взаимодействующих вычислительных процессов, работающих параллельно (одновременно). Термин охватывает совокупность вопросов [параллелизма в программировании](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC), а также создание эффективно действующих [аппаратных реализаций](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%BB%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B). Теория параллельных вычислений составляет раздел [прикладной теории алгоритмов](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%BE%D0%B2).

Существуют различные способы реализации параллельных вычислений. Например, каждый вычислительный процесс может быть реализован в виде [процесса операционной системы](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81_(%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)), либо же вычислительные процессы могут представлять собой набор [потоков выполнения](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%82%D0%BE%D0%BA_%D0%B2%D1%8B%D0%BF%D0%BE%D0%BB%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F) внутри одного процесса ОС. Параллельные программы могут физически исполняться либо последовательно на единственном [процессоре](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80) — перемежая по очереди шаги выполнения каждого вычислительного процесса, либо параллельно — выделяя каждому вычислительному процессу один или несколько процессоров (находящихся [рядом](https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C) или [распределённых](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D1%91%D0%BD%D0%BD%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F) в компьютерную [сеть](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C)).

Основная сложность при проектировании параллельных программ — обеспечить правильную последовательность взаимодействий между различными вычислительными процессами, а также координацию ресурсов, разделяемых между процессами.
# 1

**5. Кластеры (****clusters****)**

Кластер – это группа компьютеров, объединенных в локальную вычислительную сеть и способных работать в качестве единого вы-числительного ресурса. Преимущества кластерной системы перед набором независимых компьютеров очевидны. Во-первых, разработано множество диспетчерских систем пакетной обработки заданий, позволяющих послать задание на обработку кластеру в целом, а не какому-то отдельному компьютеру. Эти диспетчерские системы автоматически распределяют задания по свободным вычислительным узлам или буферизуют их при отсутствии таковых, что позволяет обеспечить более равномерную и эффективную загрузку компьютеров. Во-вторых, появляется возможность совместного использования вычислительных ресурсов нескольких компьютеров для решения одной задачи.

Кластерные технологии стали логическим продолжением развития идей, заложенных в архитектуре MPP систем. Если процессорный модуль в MPP системе представляет собой законченную вычислительную систему, то следующий шаг напрашивается сам собой: почему бы в качестве таких вычислительных узлов не использовать обычные серийно выпускаемые компьютеры. Развитие коммуникационных технологий, а именно, появление высокоскоростного сетевого оборудования и специального программного обеспечения, реализующего механизм передачи сообщений над стандартными сетевыми протоколами, сделали кластерные технологии общедоступными. Сегодня не составляет большого труда создать небольшую кластерную систему, объединив вычислительные мощности компьютеров отдельной лабо-ратории или учебного класса. Привлекательной чертой кластерных технологий является то, что они позволяют для достижения необходимой производительности объединять в единые вычислительные системы компьютеры самого разного типа, начиная от персональных компьютеров и заканчивая мощными суперкомпьютерами. Широкое распространение кластерные технологии получили как средство создания систем суперкомпь-ютерного класса из составных частей (компьютеров, процессоров и проч.) массового производства, что значительно удешевляет стоимость вычислительной системы. Производительность систем с распределенной памятью (например, мультикомпьютеры) очень сильно зависит от производительности коммуникационной среды. Коммуникационную среду можно достаточно полно охарактеризовать двумя параметрами: латентностью -временем задержки при посылке сообщения и пропускной способностью-скоростью передачи информации. Это отчасти объясняет очень высокую стоимость суперкомпьютеров. Для создания кластеров часто используются либо простые однопроцессорные персональные компьютеры, либо двух-или четырех-процессорные SMP-серверы. При этом не накладывается никаких ограничений на состав и архитектуру узлов. Каждый из узлов может функционировать под управлением своей собственной операционной системы. Чаще всего используются стандартные операционные системы из семейства Linux. В тех случаях, когда узлы кластера неоднородны, то говорят о гетерогенных кластерах. При создании кластеров можно выделить два подхода. Первый подход применяется при создании небольших кластерных систем. В кластер объединяются полнофункциональные компьютеры, которые продолжают работать и как самостоятельные единицы, например, компьютеры учебного класса или рабочие станции лаборатории. Второй подход применяется в тех случаях, когда целенаправленно создается мощный вычислительный ресурс. Тогда системные блоки компьютеров компактно размещаются в специальных стойках, а для управления системой и для запуска задач выделяется один или несколько полнофункциональных компьютеров, называемых хост-компьютерами. Разработано множество технологий соединения компьютеров в кластер. Кластерные вычисления представляют собой особую технологию высокопроизводительных вычислений, зародившуюся вместе с развитием коммуникационных средств и ставшую прекрасной альтернативной использованию суперкомпьютеров. Кластер предполагает более высокую надежность и эффективность, нежели локальная вычислительная сеть, и существенно более низкую стоимость в сравнении с другими типами параллельных вычислительных систем за счет использования типовых аппаратных и программных решений. В разряд кластерных вычислений, фактически, входят любые параллельные вычисления, где все компьютеры системы используются как один унифицированный ресурс. Существует несколько типов кластеров — кластеры высокой доступности, MPP-кластеры, высокопроизводительные кластеры, кластеры распределенной нагрузки. Появлению кластеров способствовал гигантский скачок в развитии аппаратной базы, появление и воцарение на рынке микропроцессоров и персональных компьютеров, накопление критической массы идей и методов параллельного программирования. Все это привело, в конечном счете, к решению извечной проблемы уникальности каждой параллельной вычислительной установки –разработке стандартов на создание параллельных программ для систем с общей и распределенной памятью. Добавим к этому непрерывное улучшение соотношения «цена/производительность» персональных компьютеров. В свете всех этих обстоятельств появление кластеров было неизбежным. Преимущества такого подхода к созданию вычислительных систем большой мощности, получившие признание практически сразу после первого представления первой кластерной высокопроизводительной системы, со временем только возрастали. Следует отметить, что кластеры относятся к мультикомпьютерам, согласно классификации имеют принципиальное отличительное свойство – каждый процессор системы может использовать только свою локальную память, в то время как для доступа к данным, располагаемых на других процессорах, необходимо явно выполнить операции передачи сообщений. Отметим также, что данный подход используется при построении двух важных типов многопроцессорных вычислительных систем массивно-параллельных систем (MPP) и кластеров (clusters). Кластеры могут быть образованы на базе уже существующих у пользователей отдельных компьютеров, либо же сконструированы из типовых компьютерных элементов, что обычно не требует значительных финансовых затрат. Применение кластеров может также в некоторой степени снизить проблемы, связанные с разработкой параллельных алгоритмов и программ, поскольку повышение вычислительной мощности отдельных процессоров позволяет строить кластеры из сравнительно небольшого количества (несколько десятков) отдельных компьютеров.
# 2
 Это приводит к тому, что для параллельного выполнения в алгоритмах решения вычислительных задач достаточно выделять только крупные независимые части расчетов, что, в свою очередь, снижает сложность построения параллельных методов вычислений и уменьшает потоки передаваемых данных между компьютерами кластера. Вместе с этим следует отметить, что организация взаимодействия вычислительных узлов кластера при помощи передачи сообщений обычно приводит к значительным временным задержкам, что накладывает дополнительные ограничения на тип разрабатываемых параллельныхалгоритмов и программ.

**6.**** Grid-технологии**

Grid-технологии являются развитием и обобщением идей мета-компьютинга. В качестве процессорных мощностей рассматриваются не только суперкомпьютеры, а вообще любые компьютеры. Разделяемые ресурсы: коммуникации, данные, программное обеспечение, процессорное время.

Grid–это согласованная, открытая и стандартизованная среда, которая обеспечивает гибкое, безопасное, скоординированное разделение (общий доступ) ресурсов в рамках виртуальной организации. Для Grid характерно отсутствие центра управления вычислительными ресурсами, использование открытых стандартов и нетривиальный уровень обслуживания. Вычислительные узлы Grid обычно расположены далеко друг от друга, слабо связаны между собой через интернет-каналы, и доступность того или иного из них в произвольный момент времени не гарантирована. Это накладывает дополнительные требования на управление ресурсами. Структура Grid —это виртуальная организация, образованная над пространством реальных компьютеров, сетей, административных зон. Задача виртуальной организации —создать среду, где части одного приложения, выполняемые на разных компьютерах, будут взаимодействовать между собой. Более того, подразумевается, что к системе можно динамически подключить произвольный новый ресурс — а значит, модель коммуникаций должна быть строго стандартизирована. При этом их коммуникации не должны зависеть от среды выполнения. Происходит ли вычисление в рамках одного компьютера, в локальной сети или в глобальной, объединяющей множество организаций, -это должно оставаться прозрачным для приложения. Grid - системы могут быть классифицированы точки зрения выделения вычислительных ресурсов следующим образом:

•Добровольные

•Научные

•Коммерческие

С точки зрения решаемых задач Grid - системы могут быть класс точки зрения решаемых задач _Grid-системы могут быть классифицированы следующим образом:_

- Вычислительные
- Для интенсивной обработки данных
- Семантические -для оперирования данными из различных баз данных.

Крупнейшим разработчиком Grid-технологий является Globus Alliance –сообщество разработчиков, которое распространяет и поддерживает Globus Toolkit –открытое программное обеспечение для построения Grid систем и приложений. Следует отметить, что стандарты Globus признают такие лидеры компьютерной индустрии, как IBM, Sun, Microsoft, Intel. В качестве применения Grid технологий отметим проект SETI (Search for Extraterrestrial Intelligence) –некоммерческий проект, использующий свободные ресурсы на компьютерах добровольцев, для поиска внеземного разума. Другой известный проект - расшифровка геномов, а том числе и человека.

Globus Toolkit представляет собой набор модулей для построения виртуальной организации распределенных вычислений. Каждый модуль определяет интерфейс, используемый высокоуровневыми компонентами, и имеет реализацию для различных сред выполнения. Вместе они образуют виртуальную машину Globus, в которой существуют _следующие группы модулей:_

- поиска и выделения ресурсов;
- коммуникаций; аутентификации;
- информационные;
- доступа к данным;
- создания процессов.

Важнейшая проблема, которую решают Grid технологии –разделение ресурсов. Разделение должно быть жестко контролируемо провайдерами ресурсов и потребителями, определяющим что разделяется, кому и на каких условиях разрешено разделение. Виртуальная организация –объединение отдельных специалистов, определенное вышеописанными правилами разделения. Фундаментальным свойством GRID систем является интеропе-рабельность – способность к взаимодействию различных программных и аппаратных средств. В контексте сетевых технологий интероперабельность – общность протоколов, поэтому можно сказать, что GRID архитектура –архитектура протоколов.

_Grid -систем это система, которая:_

1. Координирует управление ресурсами при отсутствии централизованного управления этими ресурсами.

2. Использует стандартные, открытые, универсальные протоколы и интерфейсы.

3. Нетривиальным образом обеспечивает качество обслуживания.

Так, например Всемирная паутина (Web) – не является Grid системой, а файлообменные системы в локальной вычислительной сети с распределенными одно ранговыми объектами без централизованного управления можно рассматривать как Grid - системы. Таким образом, у пользователей каждой из рассмотренных нами виртуальных платформ Grid появляется потенциальный доступ к сетям остальных платформ. Grid вычисления становятся все более интегрированными.
# 3

**Заключение**

Диалектическая спираль развития компьютерных технологий совершила свой очередной виток - опять, как и десять лет назад, в соответствии с требованиями жизни, в моду входят суперкомпьютерные архитектуры.

Новые технологии и требовательный рынок коммерческих применений существенно изменили облик современного суперкомпьютера. Теперь это не огромные шкафы с уникальной аппаратурой, вокруг которой колдуют шаманы от информатики, а вполне эргономичные системы с унифицированным программным обеспечением, совместимые со своими младшими собратьями. В данной работе я рассмотрела такую тему как суперкомпьютерные вычисления (параллельные, распределенные), а также кластеры и grid –технологии. Немного затронула тему использования суперкомпьютеров в современном мире и историю их развития.

**Список использованных источников**

1. Баденко В.Л. Высокопроизводительные вычисления: учеб. пособие –СПб.: Изд-во Политехн. ун-та, 2010. –180с.;

2. Левин В. К. «Отечественные суперкомпьютеры»;

3. https://ru.wikipedia.org/wiki/Параллельные\_вычисления;

4. https://ru.wikipedia.org/wiki/Кластер\_(группа\_компьютеров);

5. https://ru.wikipedia.org/wiki/Грид;

6. https://ru.wikipedia.org/wiki/Суперкомпьютер;

7. https://ru.wikipedia.org/wiki/Распределённые вычисления.

[1](#sdfootnote1anc)https://ru.wikipedia.org/wiki/Параллельные\_вычисления

[2](#sdfootnote2anc)Баденко В.Л. Высокопроизводительные вычисления: учеб. пособие –СПб.: Изд-во Политехн. ун-та, 2010. –35с.

[3](#sdfootnote3anc)Баденко В.Л. Высокопроизводительные вычисления: учеб. пособие –СПб.: Изд-во Политехн. ун-та, 2010. –44с.

[4](#sdfootnote4anc)https://ru.wikipedia.org/wiki/Грид

11

